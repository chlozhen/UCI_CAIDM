{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jarvis.train import datasets\n",
    "from jarvis.train.client import Client\n",
    "from jarvis.utils.general import tools as jtools\n",
    "from jarvis.utils.display import imshow\n",
    "from tensorflow.keras import Input, Model, models, layers, metrics\n",
    "from tensorflow import losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-11-05 18:48:23 ] CUDA_VISIBLE_DEVICES automatically set to: 3           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = jtools.get_paths('xr/breast-fgt')\n",
    "client = Client('/data/raw/xr_breast_fgt/data/ymls/client.yml')\n",
    "gen_train, gen_valid = client.create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "# xs, ys = next(gen_train)\n",
    "\n",
    "# for key, arr in xs.items():\n",
    "#     print('xs key: {} | shape = {}'.format(key.ljust(8), arr.shape))\n",
    "# for key, arr in ys.items():\n",
    "#     print('ys key: {} | shape = {}'.format(key.ljust(8), arr.shape))\n",
    "\n",
    "# imshow(xs['dat'][0])\n",
    "# imshow(xs['dat'], figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = client.get_inputs(Input)\n",
    "\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "  #  'kernel_initializer': 'he_normal'}\n",
    "\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "\n",
    "# # T1\n",
    "# l1 = conv2(48, conv1(48, conv1(48, inputs['dat'])))\n",
    "# l2 = conv2(56, conv1(56, conv1(56, l1)))\n",
    "# l3 = conv2(64, conv1(64, conv1(64, l2)))\n",
    "# l4 = conv2(80, conv1(80, conv1(80, l3)))\n",
    "# l5 = conv2(96, conv1(96, conv1(96, l4)))\n",
    "# l6 = conv2(112, conv1(112, conv1(112, l5)))\n",
    "# l7 = conv2(128, conv1(128, conv1(128, l6)))\n",
    "# f0 = layers.Reshape((1, 1, 1, 2 * 2 * 128))(l7)\n",
    "# trial = 1\n",
    "\n",
    "# # # T2\n",
    "# l1 = conv2(48, conv1(48, inputs['dat']))\n",
    "# l2 = conv2(56, conv1(56, l1))\n",
    "# l3 = conv2(64, conv1(64, l2))\n",
    "# l4 = conv2(80, conv1(80, l3))\n",
    "# l5 = conv2(96, conv1(96, l4))\n",
    "# l6 = conv2(112, conv1(112, l5))\n",
    "# l7 = conv2(128, conv1(128, l6))\n",
    "# f0 = layers.Reshape((1, 1, 1, 2 * 2 * 128))(l7)\n",
    "# trial = 2\n",
    "\n",
    "# # T3\n",
    "# l1 = conv2(48, conv1(48, inputs['dat']))\n",
    "# l2 = conv2(56, conv1(56, l1))\n",
    "# l3 = conv2(64, conv1(64, l2))\n",
    "# l4 = conv2(80, conv1(80, l3))\n",
    "# l5 = conv2(96, conv1(96, l4))\n",
    "# l6 = conv2(112, conv1(112, l5))\n",
    "# l7 = conv2(128, conv1(128, l6))\n",
    "# l8 = conv2(256, conv1(256, l7))\n",
    "# f0 = layers.Reshape((1, 1, 1, 1 * 1 * 256))(l8)\n",
    "# trial = 3\n",
    "\n",
    "# T4\n",
    "l1 = conv2(16, conv1(16, conv1(16, inputs['dat'])))\n",
    "l2 = conv2(36, conv1(36, conv1(36, l1)))\n",
    "l3 = conv2(48, conv1(48, conv1(48, l2)))\n",
    "l4 = conv2(64, conv1(64, conv1(64, l3)))\n",
    "l5 = conv2(80, conv1(80, conv1(80, l4)))\n",
    "l6 = conv2(112, conv1(112, conv1(112, l5)))\n",
    "l7 = conv2(128, conv1(128, conv1(128, l6)))\n",
    "f0 = layers.Reshape((1, 1, 1, 2 * 2 * 128))(l7)\n",
    "trial = 4\n",
    "\n",
    "logits = {}\n",
    "logits['lbl'] = layers.Conv3D(filters=1, kernel_size=(1, 1, 1), activation='sigmoid', name='lbl')(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=logits)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=5e-4),\n",
    "    loss={'lbl': losses.MeanAbsoluteError()}, metrics={'lbl':losses.MeanSquaredError()},\n",
    "    experimental_run_tf_function=False)\n",
    "\n",
    "# ***mean absolute error (MAE)\n",
    "# mean squared error (MSE)\n",
    "# Huber loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "Epoch 1/4\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0783 - mean_squared_error: 0.0143\n",
      "Epoch 2/4\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.0091WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "Epoch 1/4\n",
      "500/500 [==============================] - 52s 105ms/step - loss: 0.0717 - mean_squared_error: 0.0132\n",
      "500/500 [==============================] - 103s 206ms/step - loss: 0.0606 - mean_squared_error: 0.0091 - val_loss: 0.0717 - val_mean_squared_error: 0.0132\n",
      "Epoch 3/4\n",
      "500/500 [==============================] - 50s 101ms/step - loss: 0.0538 - mean_squared_error: 0.0076\n",
      "Epoch 4/4\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.0063WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "Epoch 1/4\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 0.0473 - mean_squared_error: 0.0061\n",
      "500/500 [==============================] - 102s 205ms/step - loss: 0.0498 - mean_squared_error: 0.0063 - val_loss: 0.0473 - val_mean_squared_error: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f38568470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=500, \n",
    "    epochs=4,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=500,\n",
    "    validation_freq=2,\n",
    "    use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.0364 - mean_squared_error: 0.0035\n",
      "Epoch 2/2\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0029WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.0422 - mean_squared_error: 0.0054\n",
      "500/500 [==============================] - 101s 201ms/step - loss: 0.0332 - mean_squared_error: 0.0029 - val_loss: 0.0422 - val_mean_squared_error: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e107d48d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11052020 - (T4) - trained on 4 epochs, lr: 5e-4\n",
    "#train again on lower lr: 5e-5\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=5e-5),\n",
    "    loss={'lbl': losses.MeanAbsoluteError()}, metrics={'lbl':losses.MeanSquaredError()},\n",
    "    experimental_run_tf_function=False)\n",
    "\n",
    "model.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=500, \n",
    "    epochs=2,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=500,\n",
    "    validation_freq=2,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_trial_{}.hdf5'.format(trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATE       MODEL         EPOCH    LR      RESULTS\n",
    "#11042020 - (SU OG)       4        5e-5    loss: 0.0494 - mean_squared_error: 0.0060 - val_loss: 0.0643 - val_mean_squared_error: 0.0092\n",
    "#11052020 - (T1)          4        5e-5    loss: 0.0436 - mean_squared_error: 0.0047 - val_loss: 0.0590 - val_mean_squared_error: 0.0082\n",
    "#11052020 - (T2)          4        5e-5    loss: 0.0417 - mean_squared_error: 0.0043 - val_loss: 0.0613 - val_mean_squared_error: 0.0089\n",
    "#11052020 - (T3)          4        5e-5    loss: 0.0506 - mean_squared_error: 0.0061 - val_loss: 0.0657 - val_mean_squared_error: 0.0099\n",
    "#11052020 - (T3)          6        5e-5    loss: 0.0455 - mean_squared_error: 0.0049 - val_loss: 0.0626 - val_mean_squared_error: 0.0090\n",
    "#11052020 - (T2)          6        5e-5    loss: 0.0344 - mean_squared_error: 0.0028 - val_loss: 0.0635 - val_mean_squared_error: 0.0100\n",
    "#11052020 - (T1)          6        5e-5    loss: 0.0362 - mean_squared_error: 0.0029 - val_loss: 0.0667 - val_mean_squared_error: 0.0097\n",
    "#11052020 - (T4)          6        5e-4    loss: 0.0435 - mean_squared_error: 0.0050 - val_loss: 0.0692 - val_mean_squared_error: 0.0093\n",
    "\n",
    "#best so far\n",
    "#11052020 - (T4)          4        5e-4    loss: 0.0498 - mean_squared_error: 0.0063 - val_loss: 0.0473 - val_mean_squared_error: 0.0061\n",
    "#    cont - (T4)          2        5e-5    loss: 0.0332 - mean_squared_error: 0.0029 - val_loss: 0.0422 - val_mean_squared_error: 0.0054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train, test_valid = client.create_generators(test=True)\n",
    "# # xs, ys = next(test_valid)\n",
    "# xs, ys = next(gen_valid)\n",
    "# logits = model.predict(xs['dat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mse(a, b):\n",
    "#     mse = ((a - b)**2).mean()\n",
    "#     return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #evaluation\n",
    "# model = models.load_model('model_11042020.hdf5', compile=False)\n",
    "\n",
    "# losses = []\n",
    "\n",
    "# for x, y in gen_valid:\n",
    "#     # --- Predict Percentage\n",
    "#     logits = model.predict(x['dat'])\n",
    "#     if type(logits) is dict:\n",
    "#         logits = logits['lbl']\n",
    "        \n",
    "#     pred = logits\n",
    "#     trues = y['lbl']\n",
    "    \n",
    "#     loss = mse(trues, pred)\n",
    "# #     print('.', end='')\n",
    "#     losses.append(loss)\n",
    "\n",
    "# losses = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
